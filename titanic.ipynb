{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 1. INTRODUCTION\nOur Objectif in this competition is to use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom collections import Counter\n\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n\nsns.set(style='white', context='notebook', palette='deep')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:27.915748Z","iopub.execute_input":"2022-02-08T18:47:27.916417Z","iopub.status.idle":"2022-02-08T18:47:27.926855Z","shell.execute_reply.started":"2022-02-08T18:47:27.916375Z","shell.execute_reply":"2022-02-08T18:47:27.925923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Load data","metadata":{}},{"cell_type":"code","source":"# Load data\n##### Load train and Test set\n\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:28.865174Z","iopub.execute_input":"2022-02-08T18:47:28.865482Z","iopub.status.idle":"2022-02-08T18:47:28.884789Z","shell.execute_reply.started":"2022-02-08T18:47:28.865448Z","shell.execute_reply":"2022-02-08T18:47:28.883829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:29.024601Z","iopub.execute_input":"2022-02-08T18:47:29.024884Z","iopub.status.idle":"2022-02-08T18:47:29.041032Z","shell.execute_reply.started":"2022-02-08T18:47:29.024847Z","shell.execute_reply":"2022-02-08T18:47:29.04047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This amazing checking outlier is taken from [here](https://www.kaggle.com/yassineghouzam/titanic-top-4-with-ensemble-modeling?scriptVersionId=1416377&cellId=7) please go and check it","metadata":{}},{"cell_type":"code","source":"# Outlier detection \n\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:29.294982Z","iopub.execute_input":"2022-02-08T18:47:29.295313Z","iopub.status.idle":"2022-02-08T18:47:29.309078Z","shell.execute_reply.started":"2022-02-08T18:47:29.295252Z","shell.execute_reply":"2022-02-08T18:47:29.308031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I decided to detect outliers from the numerical values features (Age, SibSp, Sarch and Fare). Then, i considered outliers as rows that have at least two outlied numerical values.","metadata":{}},{"cell_type":"code","source":"train.loc[Outliers_to_drop] # Show the outliers rows","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:29.606644Z","iopub.execute_input":"2022-02-08T18:47:29.606906Z","iopub.status.idle":"2022-02-08T18:47:29.623555Z","shell.execute_reply.started":"2022-02-08T18:47:29.606869Z","shell.execute_reply":"2022-02-08T18:47:29.622974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We detect 10 outliers. The 28, 89 and 342 passenger have an high Ticket Fare\n\nThe 7 others have very high values of SibSP.","metadata":{}},{"cell_type":"code","source":"# Drop outliers\ntrain = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:37.882572Z","iopub.execute_input":"2022-02-08T18:47:37.882864Z","iopub.status.idle":"2022-02-08T18:47:37.888683Z","shell.execute_reply.started":"2022-02-08T18:47:37.882831Z","shell.execute_reply":"2022-02-08T18:47:37.887841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Join train and test dfs in order to obtain the same number of features during categorical conversion\ndf =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:38.405416Z","iopub.execute_input":"2022-02-08T18:47:38.405694Z","iopub.status.idle":"2022-02-08T18:47:38.414918Z","shell.execute_reply.started":"2022-02-08T18:47:38.405667Z","shell.execute_reply":"2022-02-08T18:47:38.413985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's check for messing values.","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:38.819152Z","iopub.execute_input":"2022-02-08T18:47:38.81948Z","iopub.status.idle":"2022-02-08T18:47:38.827803Z","shell.execute_reply.started":"2022-02-08T18:47:38.819446Z","shell.execute_reply":"2022-02-08T18:47:38.827217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:38.996918Z","iopub.execute_input":"2022-02-08T18:47:38.997828Z","iopub.status.idle":"2022-02-08T18:47:39.006633Z","shell.execute_reply.started":"2022-02-08T18:47:38.997787Z","shell.execute_reply":"2022-02-08T18:47:39.005985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age and Cabin have an important part in missing values.","metadata":{}},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:39.361708Z","iopub.execute_input":"2022-02-08T18:47:39.362013Z","iopub.status.idle":"2022-02-08T18:47:39.368109Z","shell.execute_reply.started":"2022-02-08T18:47:39.361981Z","shell.execute_reply":"2022-02-08T18:47:39.367594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:39.543888Z","iopub.execute_input":"2022-02-08T18:47:39.544174Z","iopub.status.idle":"2022-02-08T18:47:39.572211Z","shell.execute_reply.started":"2022-02-08T18:47:39.544142Z","shell.execute_reply":"2022-02-08T18:47:39.57163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Feature analysis\n#### 3.1 For numerical variables","metadata":{}},{"cell_type":"code","source":"# Correlation matrix between numerical variables\ncor_numeric = sns.heatmap(train[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].\n                          corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:39.845438Z","iopub.execute_input":"2022-02-08T18:47:39.845845Z","iopub.status.idle":"2022-02-08T18:47:40.173667Z","shell.execute_reply.started":"2022-02-08T18:47:39.845815Z","shell.execute_reply":"2022-02-08T18:47:40.173089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only Fare feature seems to have a significative correlation with the survival probability.","metadata":{}},{"cell_type":"markdown","source":"#### Checking the death frequency of the classes of different attributes","metadata":{}},{"cell_type":"markdown","source":"#### SibSp","metadata":{}},{"cell_type":"code","source":"# Explore SibSp feature vs Survived\ng = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=train,kind=\"bar\", size = 5 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:40.502688Z","iopub.execute_input":"2022-02-08T18:47:40.503084Z","iopub.status.idle":"2022-02-08T18:47:40.989374Z","shell.execute_reply.started":"2022-02-08T18:47:40.503054Z","shell.execute_reply":"2022-02-08T18:47:40.988805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that passengers having a lot of siblings/spouses have less chance to survive, and the passengers having a less of siblings/spouses have more chance to survive.","metadata":{}},{"cell_type":"markdown","source":"#### Parch","metadata":{}},{"cell_type":"code","source":"# Explore Parch feature vs Survived\ng  = sns.factorplot(x=\"Parch\",y=\"Survived\",data=train,kind=\"bar\", size = 5 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:41.066134Z","iopub.execute_input":"2022-02-08T18:47:41.066543Z","iopub.status.idle":"2022-02-08T18:47:41.552567Z","shell.execute_reply.started":"2022-02-08T18:47:41.066514Z","shell.execute_reply":"2022-02-08T18:47:41.551643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Small families have more chance to survive.","metadata":{}},{"cell_type":"markdown","source":"#### Age","metadata":{}},{"cell_type":"code","source":"# Explore Age vs Survived\ng = sns.FacetGrid(train, col='Survived')\ng = g.map(sns.distplot, \"Age\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:41.670655Z","iopub.execute_input":"2022-02-08T18:47:41.670962Z","iopub.status.idle":"2022-02-08T18:47:42.313343Z","shell.execute_reply.started":"2022-02-08T18:47:41.670926Z","shell.execute_reply":"2022-02-08T18:47:42.312485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age distribution seems to be a Heavy-tailed distribution.\n\nWe notice that age distributions are not the same in the survived and not survived subpopulations. Indeed, there is a peak corresponding to passengers between 0 and 5, that have survived. We also see that passengers between 60-80 have less survived.\n\nIt seems that very young passengers have more chance to survive.","metadata":{}},{"cell_type":"markdown","source":"#### Fare","metadata":{}},{"cell_type":"code","source":"# Explore Fare distribution \ng = sns.distplot(df[\"Fare\"], color=\"b\", label=\"Skewness : %.2f\"%(df[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:54.148431Z","iopub.execute_input":"2022-02-08T18:47:54.148708Z","iopub.status.idle":"2022-02-08T18:47:54.540212Z","shell.execute_reply.started":"2022-02-08T18:47:54.148681Z","shell.execute_reply":"2022-02-08T18:47:54.539371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, Fare distribution is very skewed. This can lead to overweigth very high values in the model, even if it is scaled.\n\nMany financial models that attempt to predict the future performance of an asset assume a normal distribution, in which measures of central tendency are equal. If the data are skewed, this kind of model will always underestimate skewness risk in its predictions. The more skewed the data, the less accurate this financial model will be.\n\nIn this case, it is better to transform it with the log function to reduce this skew.","metadata":{}},{"cell_type":"code","source":"# Apply log to Fare to reduce skewness distribution\ndf[\"Fare\"] = df[\"Fare\"].map(lambda i: np.log(i) if i > 0 else 0)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:54.541992Z","iopub.execute_input":"2022-02-08T18:47:54.542755Z","iopub.status.idle":"2022-02-08T18:47:54.549939Z","shell.execute_reply.started":"2022-02-08T18:47:54.542706Z","shell.execute_reply":"2022-02-08T18:47:54.54936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.distplot(df[\"Fare\"], color=\"r\", label=\"Skewness : %.2f\"%(df[\"Fare\"].skew()))\ng = g.legend(loc=\"best\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:54.73919Z","iopub.execute_input":"2022-02-08T18:47:54.739722Z","iopub.status.idle":"2022-02-08T18:47:55.266777Z","shell.execute_reply.started":"2022-02-08T18:47:54.739679Z","shell.execute_reply":"2022-02-08T18:47:55.266177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Skewness is clearly reduced after the log transformation","metadata":{}},{"cell_type":"markdown","source":"#### 3.2 Categorical values","metadata":{}},{"cell_type":"markdown","source":"#### Sex","metadata":{}},{"cell_type":"code","source":"g = sns.barplot(x=\"Sex\",y=\"Survived\",data=train)\ng = g.set_ylabel(\"Survival Probability\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:55.47805Z","iopub.execute_input":"2022-02-08T18:47:55.478623Z","iopub.status.idle":"2022-02-08T18:47:55.732066Z","shell.execute_reply.started":"2022-02-08T18:47:55.478582Z","shell.execute_reply":"2022-02-08T18:47:55.731317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's clearly obvious that Male have less chance to survive than Female.","metadata":{}},{"cell_type":"markdown","source":"#### Pclass","metadata":{}},{"cell_type":"code","source":"# Explore Pclass vs Survived\ng = sns.factorplot(x=\"Pclass\",y=\"Survived\",data=train,kind=\"bar\", size = 4 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:56.223054Z","iopub.execute_input":"2022-02-08T18:47:56.223688Z","iopub.status.idle":"2022-02-08T18:47:56.600812Z","shell.execute_reply.started":"2022-02-08T18:47:56.223638Z","shell.execute_reply":"2022-02-08T18:47:56.599869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The passenger survival is not the same in the 3 classes. First class passengers have more chance to survive than second class and third class passengers.","metadata":{}},{"cell_type":"markdown","source":"#### Embarked","metadata":{}},{"cell_type":"code","source":"# Explore Embarked vs Survived \ng = sns.factorplot(x=\"Embarked\", y=\"Survived\",  data=train,\n                   size=4, kind=\"bar\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:57.00878Z","iopub.execute_input":"2022-02-08T18:47:57.009298Z","iopub.status.idle":"2022-02-08T18:47:57.382108Z","shell.execute_reply.started":"2022-02-08T18:47:57.009233Z","shell.execute_reply":"2022-02-08T18:47:57.381453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that passenger coming from Cherbourg (C) have more chance to survive.","metadata":{}},{"cell_type":"markdown","source":"### 4. Filling missing Values","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:57.511762Z","iopub.execute_input":"2022-02-08T18:47:57.512223Z","iopub.status.idle":"2022-02-08T18:47:57.520235Z","shell.execute_reply.started":"2022-02-08T18:47:57.512165Z","shell.execute_reply":"2022-02-08T18:47:57.519533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"418 Survived missing values coming from test data.\n\nSince we have two missing values for Embarked, I decided to fill them with the most fequent value of \"Embarked\".\n\nSince we have one messing values for Fare, so I decide to fill them with the median value of \"Fare\".","metadata":{}},{"cell_type":"code","source":"#Fill Fare missing values with the median value\ndf[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median())\n\n#Fill Embarked nan values of df with most frequent value\ndf[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:57.864771Z","iopub.execute_input":"2022-02-08T18:47:57.865192Z","iopub.status.idle":"2022-02-08T18:47:57.87127Z","shell.execute_reply.started":"2022-02-08T18:47:57.865162Z","shell.execute_reply":"2022-02-08T18:47:57.870271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:58.310465Z","iopub.execute_input":"2022-02-08T18:47:58.311028Z","iopub.status.idle":"2022-02-08T18:47:58.319544Z","shell.execute_reply.started":"2022-02-08T18:47:58.31099Z","shell.execute_reply":"2022-02-08T18:47:58.318597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we see, Age column contains 256 missing values in the whole df.\n\nSince there is subpopulations that have more chance to survive (children for example), it is preferable to keep the age feature and to impute the missing values.\n\nTo adress this problem, i looked at the most correlated features with Age (Sex, Parch , Pclass and SibSP).","metadata":{}},{"cell_type":"code","source":"# convert Sex into categorical value 0 for male and 1 for female\ndf[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\":1})","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:58.941182Z","iopub.execute_input":"2022-02-08T18:47:58.941807Z","iopub.status.idle":"2022-02-08T18:47:58.947295Z","shell.execute_reply.started":"2022-02-08T18:47:58.941766Z","shell.execute_reply":"2022-02-08T18:47:58.94634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.heatmap(df[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),cmap=\"BrBG\",annot=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:59.53032Z","iopub.execute_input":"2022-02-08T18:47:59.530581Z","iopub.status.idle":"2022-02-08T18:47:59.860978Z","shell.execute_reply.started":"2022-02-08T18:47:59.530555Z","shell.execute_reply":"2022-02-08T18:47:59.860141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age is not correlated with Sex, but is negatively correlated with Pclass, Parch and SibSp. So I will use Pclass, Parch and SibSp to impute the missing values of Age.","metadata":{}},{"cell_type":"code","source":"# Filling missing value of Age \n\n## Fill Age with the median age of similar rows according to Pclass, Parch and SibSp\n# Index of NaN age rows\nindex_NaN_age = list(df[\"Age\"][df[\"Age\"].isnull()].index)\n\nfor i in index_NaN_age :\n    age_med = df[\"Age\"].median()\n    age_pred = df[\"Age\"][((df['SibSp'] == df.iloc[i][\"SibSp\"]) & (df['Parch'] == df.iloc[i][\"Parch\"]) & (df['Pclass'] == df.iloc[i][\"Pclass\"]))].median()\n    if not np.isnan(age_pred) :\n        df['Age'].iloc[i] = age_pred\n    else :\n        df['Age'].iloc[i] = age_med","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:47:59.998057Z","iopub.execute_input":"2022-02-08T18:47:59.998347Z","iopub.status.idle":"2022-02-08T18:48:00.425927Z","shell.execute_reply.started":"2022-02-08T18:47:59.998318Z","shell.execute_reply":"2022-02-08T18:48:00.424816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Cabin Have a lot of missing values, I decide to drop this column.","metadata":{}},{"cell_type":"code","source":"# Drop Cabin variable\ndf.drop(labels = [\"Cabin\"], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:00.502351Z","iopub.execute_input":"2022-02-08T18:48:00.502658Z","iopub.status.idle":"2022-02-08T18:48:00.509214Z","shell.execute_reply.started":"2022-02-08T18:48:00.502618Z","shell.execute_reply":"2022-02-08T18:48:00.508601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. Feature engineering","metadata":{}},{"cell_type":"code","source":"df[\"Name\"].head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:01.238088Z","iopub.execute_input":"2022-02-08T18:48:01.238553Z","iopub.status.idle":"2022-02-08T18:48:01.245431Z","shell.execute_reply.started":"2022-02-08T18:48:01.238512Z","shell.execute_reply":"2022-02-08T18:48:01.244766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The Name feature contains information on passenger's title.\n\nSince some passenger with distingused title may be preferred during the evacuation, it is interesting to add them to the model.","metadata":{}},{"cell_type":"code","source":"# Get Title from Name\ndf_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in df[\"Name\"]]\ndf[\"Title\"] = pd.Series(df_title)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:02.176132Z","iopub.execute_input":"2022-02-08T18:48:02.176927Z","iopub.status.idle":"2022-02-08T18:48:02.18369Z","shell.execute_reply.started":"2022-02-08T18:48:02.176881Z","shell.execute_reply":"2022-02-08T18:48:02.182783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = sns.countplot(x=\"Title\",data=df)\ng = plt.setp(g.get_xticklabels(), rotation=45) ","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:02.644158Z","iopub.execute_input":"2022-02-08T18:48:02.644959Z","iopub.status.idle":"2022-02-08T18:48:02.975132Z","shell.execute_reply.started":"2022-02-08T18:48:02.644919Z","shell.execute_reply":"2022-02-08T18:48:02.97425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is 17 titles in the df, most of them are very rare and we can group them in 4 categories.","metadata":{}},{"cell_type":"code","source":"# Convert to categorical values Title \ndf[\"Title\"] = df[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndf[\"Title\"] = df[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ndf[\"Title\"] = df[\"Title\"].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:03.574572Z","iopub.execute_input":"2022-02-08T18:48:03.575219Z","iopub.status.idle":"2022-02-08T18:48:03.586094Z","shell.execute_reply.started":"2022-02-08T18:48:03.575172Z","shell.execute_reply":"2022-02-08T18:48:03.585164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop Name variable\ndf.drop(labels = [\"Name\"], axis = 1, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:04.058428Z","iopub.execute_input":"2022-02-08T18:48:04.059003Z","iopub.status.idle":"2022-02-08T18:48:04.064355Z","shell.execute_reply.started":"2022-02-08T18:48:04.058966Z","shell.execute_reply":"2022-02-08T18:48:04.063674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert to indicator values Embarked \ndf = pd.get_dummies(df, columns = [\"Embarked\"], prefix=\"Em\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:04.500199Z","iopub.execute_input":"2022-02-08T18:48:04.5008Z","iopub.status.idle":"2022-02-08T18:48:04.509719Z","shell.execute_reply.started":"2022-02-08T18:48:04.500756Z","shell.execute_reply":"2022-02-08T18:48:04.508951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.get_dummies(df, columns = [\"Ticket\"], prefix=\"T\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:05.221038Z","iopub.execute_input":"2022-02-08T18:48:05.221351Z","iopub.status.idle":"2022-02-08T18:48:05.242915Z","shell.execute_reply.started":"2022-02-08T18:48:05.221317Z","shell.execute_reply":"2022-02-08T18:48:05.241972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:05.90073Z","iopub.execute_input":"2022-02-08T18:48:05.901412Z","iopub.status.idle":"2022-02-08T18:48:05.920571Z","shell.execute_reply.started":"2022-02-08T18:48:05.901369Z","shell.execute_reply":"2022-02-08T18:48:05.919652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 6. Build Our Model","metadata":{}},{"cell_type":"code","source":"## Separate train and test data\n\ntrain = df[:len(train)]\ntest = df[len(train):]\ntest.drop(labels=[\"Survived\"],axis = 1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:13.11049Z","iopub.execute_input":"2022-02-08T18:48:13.11076Z","iopub.status.idle":"2022-02-08T18:48:13.118671Z","shell.execute_reply.started":"2022-02-08T18:48:13.110732Z","shell.execute_reply":"2022-02-08T18:48:13.117681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Separate train features and label \n\ntrain[\"Survived\"] = train[\"Survived\"].astype(int)\n\nY_train = train[\"Survived\"]\n\nX_train = train.drop(labels = [\"Survived\"],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:13.875305Z","iopub.execute_input":"2022-02-08T18:48:13.875606Z","iopub.status.idle":"2022-02-08T18:48:13.884264Z","shell.execute_reply.started":"2022-02-08T18:48:13.875571Z","shell.execute_reply":"2022-02-08T18:48:13.883584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I compared 10 popular classifiers and evaluate the mean accuracy of each of them by a stratified kfold cross validation procedure.\n\n* SVC\n* Decision Tree\n* AdaBoost\n* Random Forest\n* Extra Trees\n* Gradient Boosting\n* Multiple layer perceprton (neural network)\n* KNN\n* Logistic regression\n* Linear Discriminant Analysis","metadata":{}},{"cell_type":"code","source":"# Cross validate model with Kfold stratified cross val\nkfold = StratifiedKFold(n_splits=10)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:16.395169Z","iopub.execute_input":"2022-02-08T18:48:16.395463Z","iopub.status.idle":"2022-02-08T18:48:16.400159Z","shell.execute_reply.started":"2022-02-08T18:48:16.395434Z","shell.execute_reply":"2022-02-08T18:48:16.399122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modeling step Test differents algorithms \nrandom_state = 2\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\n\ncv_results = []\nfor classifier in classifiers :\n    cv_results.append(cross_val_score(classifier, X_train, y = Y_train, scoring = \"accuracy\", cv = kfold, n_jobs=4))\n\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n    \ncv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n\ng = sns.barplot(\"CrossValMeans\",\"Algorithm\",data = cv_res, palette=\"Set3\",orient = \"h\",**{'xerr':cv_std})\ng.set_xlabel(\"Mean Accuracy\")\ng = g.set_title(\"Cross validation scores\")","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:48:17.173334Z","iopub.execute_input":"2022-02-08T18:48:17.174195Z","iopub.status.idle":"2022-02-08T18:48:59.585639Z","shell.execute_reply.started":"2022-02-08T18:48:17.174154Z","shell.execute_reply":"2022-02-08T18:48:59.584575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I decided to choose RandomForestClassifier for the ensemble modeling.","metadata":{}},{"cell_type":"code","source":"#Create a LinearDiscriminantAnalysis Classifier\nETC=RandomForestClassifier(random_state=random_state)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nETC.fit(X_train,Y_train)\n\ny_pred=ETC.predict(test)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:53:31.143523Z","iopub.execute_input":"2022-02-08T18:53:31.143868Z","iopub.status.idle":"2022-02-08T18:53:31.644121Z","shell.execute_reply.started":"2022-02-08T18:53:31.143835Z","shell.execute_reply":"2022-02-08T18:53:31.643349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Create Sample Submission file and submit\npred = pd.DataFrame(y_pred)\nsubmession = pd.read_csv(\"../input/titanic/gender_submission.csv\")\ndf = pd.concat([submession[\"PassengerId\"], pred], axis = 1)\ndf.columns = [\"PassengerId\", \"Survived\"]\ndf.to_csv(\"gender_submission_rfc.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T18:49:27.723262Z","iopub.execute_input":"2022-02-08T18:49:27.723963Z","iopub.status.idle":"2022-02-08T18:49:27.739405Z","shell.execute_reply.started":"2022-02-08T18:49:27.723921Z","shell.execute_reply":"2022-02-08T18:49:27.738259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}